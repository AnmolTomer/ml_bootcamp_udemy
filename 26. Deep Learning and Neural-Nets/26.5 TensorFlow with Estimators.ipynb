{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow with Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw previously how to build a full Multi-Layer Perceptron model with full Sessions in Tensorflow. Unfortunately this was an extremely involved process. However developers have created Estimators that have an easier to use workflow!\n",
    "\n",
    "It is much easier to use, but you sacrifice some level of customization of your model. Let's go ahead and explore it!\n",
    "\n",
    "These estimator objects allows us to quickly create models without needing to manually define the Graph as we did in last notebook.\n",
    "\n",
    "When working with MNIST dataset we had to manually define the graph and session, which is not how it's done when developers do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Steps :\n",
    "    1. Read in data (normalize if necessary)\n",
    "    2. Train/Test split the data, just like SkLearn\n",
    "    3. Create Estimator Feature Columns (a list of specialized feature columns)\n",
    "    4. Create Input Estimator function (organizing training data)\n",
    "    5. Train Estimator model\n",
    "    6. Predict with new Test Input Function\n",
    "\n",
    "We'll go over performing all of the above steps with TF estimator objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T12:33:23.881810Z",
     "start_time": "2019-06-12T12:33:23.876772Z"
    }
   },
   "source": [
    "## Get the Data\n",
    "\n",
    "We will the iris data set.\n",
    "\n",
    "Let's get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:14.983850Z",
     "start_time": "2019-06-12T13:02:14.675591Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:15.091526Z",
     "start_time": "2019-06-12T13:02:15.074572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:18.038122Z",
     "start_time": "2019-06-12T13:02:18.034093Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['sepal_length','sepal_width','petal_length','petal_width','target']\n",
    "# Reassigning column names, as it produces an error due to spaces in TF estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:19.213786Z",
     "start_time": "2019-06-12T13:02:19.206805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2     0.0\n",
       "1           4.9          3.0           1.4          0.2     0.0\n",
       "2           4.7          3.2           1.3          0.2     0.0\n",
       "3           4.6          3.1           1.5          0.2     0.0\n",
       "4           5.0          3.6           1.4          0.2     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:20.057025Z",
     "start_time": "2019-06-12T13:02:20.053037Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "y = df['target'].apply(int) # Making target column as integer, other values can be floating points without any issues.\n",
    "# Classes are in an organized manner right now, we would have to shuffle during training, else there may be test won't \n",
    "# make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:22.279899Z",
     "start_time": "2019-06-12T13:02:21.644550Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:23.425779Z",
     "start_time": "2019-06-12T13:02:23.420792Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T12:36:05.308643Z",
     "start_time": "2019-06-12T12:36:05.304650Z"
    }
   },
   "source": [
    "# Estimators\n",
    "\n",
    "Let's show you how to use the simpler Estimator interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:26.208282Z",
     "start_time": "2019-06-12T13:02:25.077013Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:28.081465Z",
     "start_time": "2019-06-12T13:02:28.076513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:29.041865Z",
     "start_time": "2019-06-12T13:02:29.037875Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "\n",
    "for col in X.columns:\n",
    "    feat_cols.append(tf.feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:02:29.428733Z",
     "start_time": "2019-06-12T13:02:29.424702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='sepal_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sepal_width', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='petal_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='petal_width', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols # Specialized numeric column objects where there is a key, and key syncs up with column name inside the Pd DF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:18.195479Z",
     "start_time": "2019-06-12T13:43:18.190492Z"
    }
   },
   "outputs": [],
   "source": [
    "# there is also a pandas_input_fn we'll see in the exercise!!\n",
    "# We create 2 input function, one for training and another for evaluation, both are similar with train,test data being different\n",
    "# input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=5,shuffle=True)\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=20,num_epochs=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size can be chosen to serve data to NN in batches, to avoid sending all data at once as that network may just crash when trying to compute the gradient. Play around with it, if getting error like empty or None predictions in TensorFlow.\n",
    "\n",
    "- Number of epochs, epoch is when we have gone through all of our training data one time. What above means that num_epoch is basically if we have gone over every single training point atleast 5 times then we are done training tf.estimator.\n",
    "\n",
    "- shuffle to have random data as target labels here are sorted in order, we already did a shuffle above when we used train_test_split by default, but doesn't hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:19.601649Z",
     "start_time": "2019-06-12T13:43:19.594668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpn0z75spy\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpn0z75spy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A76638B8D0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# classifier = tf.estimator.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3,feature_columns=feat_cols)\n",
    "classifier = tf.estimator.DNNClassifier(hidden_units=[10, 20, 10,15,20,25,30], n_classes=3,feature_columns=feat_cols)\n",
    "\n",
    "# Creating the estimator, DNN = Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hidden units, Define a list, where each number in the list defines a layer and number of neurons in that layer. [10, 20, 10] means that there is input layer, then hidden layer 0 with 10 neurons, after that hidden layer 1 with 20 neurons, after that is hidden layer 2 with 10 neurons followed by output layer. \n",
    "\n",
    "- n_classes, Tells how many classes are expected, as there are 3 species we set this to 3.\n",
    "\n",
    "- Feature columns, list of numeric columns we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:26.938088Z",
     "start_time": "2019-06-12T13:43:22.107013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpn0z75spy\\model.ckpt.\n",
      "INFO:tensorflow:loss = 23.804474, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 27 into C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpn0z75spy\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.072151.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x2a76638b400>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=input_func,steps=50) # Define how many steps you want to train for \n",
    "# Training the estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crucial Steps in the above process are :\n",
    "\n",
    "- Creating the feature columns list\n",
    "- Creating the input function\n",
    "- Creating the estimator object\n",
    "- Training the estimator\n",
    "\n",
    "It might look a lot of these are single liners, but there is a lot going on behind the scenes, like creation of session and graph that we previously created manually in the last notebook. This now, makes the process much simpler.\n",
    "\n",
    "Once, the above steps are done classifier is trained we are in a very similar position as calling .fit on SciKit-Learn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "**Use the predict method from the classifier model to create predictions from X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:27.065711Z",
     "start_time": "2019-06-12T13:43:27.060725Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating an input function similar to what we made above, here we pass in test data and do not pass y.\n",
    "\n",
    "- We do not pass y_test as we compare this against y_test, using error matrix.\n",
    "\n",
    "- We feed in all the test in one go, as we do not train here but just run the inputs of X_test and see the result, as our classifier has already been trained on train data, and see what prediction is given with X_test as input.\n",
    "\n",
    "- Shuffle is false as there is no logical need to shuffle anything, anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:30.581510Z",
     "start_time": "2019-06-12T13:43:29.979033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpn0z75spy\\model.ckpt-27\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "note_predictions = list(classifier.predict(input_fn=pred_fn))\n",
    "# We create predictions in a list, where we have classifier.predict with input_fn is prediction function we created.\n",
    "# Classifier is just a generator and needs to be typecast into a list to see the results.\n",
    "# Calls the mode, creates the graphs and finishes up running the classifier on pred_fn as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:32.920083Z",
     "start_time": "2019-06-12T13:43:32.899139Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logits': array([-3.6043298,  2.7369003,  2.5462687], dtype=float32),\n",
       "  'probabilities': array([0.00096386, 0.54698634, 0.45204976], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 3.0936365, -1.7291112, -3.0589406], dtype=float32),\n",
       "  'probabilities': array([0.98992985, 0.00796364, 0.00210656], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.276264 ,  1.7506222,  1.5753479], dtype=float32),\n",
       "  'probabilities': array([0.00960109, 0.53848654, 0.45191237], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.4964437,  1.9128118,  1.7357835], dtype=float32),\n",
       "  'probabilities': array([0.00657554, 0.5405638 , 0.45286062], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 3.0629327, -1.70687  , -3.0233636], dtype=float32),\n",
       "  'probabilities': array([0.98935854, 0.00839179, 0.00224962], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.2731764,  1.7475202,  1.572151 ], dtype=float32),\n",
       "  'probabilities': array([0.00966054, 0.53847754, 0.4518619 ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.7062595,  2.0712056,  1.889739 ], dtype=float32),\n",
       "  'probabilities': array([0.00456851, 0.5427516 , 0.45267984], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.2339156,  1.717428 ,  1.5438956], dtype=float32),\n",
       "  'probabilities': array([0.01033854, 0.5376579 , 0.45200357], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 2.6484892, -1.4793469, -2.6477413], dtype=float32),\n",
       "  'probabilities': array([0.97930896, 0.01578422, 0.00490677], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([ 2.4404597, -1.3642619, -2.4622147], dtype=float32),\n",
       "  'probabilities': array([0.97116405, 0.02162335, 0.00721254], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.5811465,  1.9774626,  1.7975914], dtype=float32),\n",
       "  'probabilities': array([0.00567576, 0.54175454, 0.45256972], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.1477692,  1.6571307,  1.4838709], dtype=float32),\n",
       "  'probabilities': array([0.01194808, 0.5367167 , 0.4513353 ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.8747098,  2.1965663,  2.013365 ], dtype=float32),\n",
       "  'probabilities': array([0.00341209, 0.5438108 , 0.45277712], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.0725312,  1.5994757,  1.4274393], dtype=float32),\n",
       "  'probabilities': array([0.01361558, 0.5355114 , 0.45087302], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.6424997,  2.0220127,  1.8426814], dtype=float32),\n",
       "  'probabilities': array([0.00510707, 0.54193115, 0.45296177], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.3187625,  1.7830157,  1.6072987], dtype=float32),\n",
       "  'probabilities': array([0.00891627, 0.5389677 , 0.45211598], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.4777672,  1.9009887,  1.7227025], dtype=float32),\n",
       "  'probabilities': array([0.00678166, 0.54076153, 0.45245677], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.6893685,  2.0570588,  1.8789344], dtype=float32),\n",
       "  'probabilities': array([0.00470472, 0.5418525 , 0.45344284], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.2265806,  1.7135439,  1.5389289], dtype=float32),\n",
       "  'probabilities': array([0.01045908, 0.53785825, 0.4516827 ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.9041436,  2.2178898,  2.0349395], dtype=float32),\n",
       "  'probabilities': array([0.0032434 , 0.54384077, 0.45291576], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 3.0801299, -1.7194827, -3.0437963], dtype=float32),\n",
       "  'probabilities': array([0.9896847 , 0.00814801, 0.00216725], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.0244935,  1.5646095,  1.3933518], dtype=float32),\n",
       "  'probabilities': array([0.01476991, 0.5346943 , 0.45053577], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.5052948,  1.9228989,  1.7443671], dtype=float32),\n",
       "  'probabilities': array([0.00645738, 0.54099864, 0.452544  ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.5725498,  1.9720404,  1.7925656], dtype=float32),\n",
       "  'probabilities': array([0.00575439, 0.54161394, 0.45263165], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.6723921,  2.0456119,  1.8646508], dtype=float32),\n",
       "  'probabilities': array([0.00484593, 0.54247564, 0.45267847], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.0777037,  1.6030195,  1.4310348], dtype=float32),\n",
       "  'probabilities': array([0.01349871, 0.53556216, 0.45093912], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 3.1095395, -1.7400556, -3.0768182], dtype=float32),\n",
       "  'probabilities': array([0.99020797, 0.00775486, 0.00203716], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.031192 ,  1.5713459,  1.4056307], dtype=float32),\n",
       "  'probabilities': array([0.01453926, 0.53346366, 0.45199707], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-3.3811657,  2.570872 ,  2.3811903], dtype=float32),\n",
       "  'probabilities': array([0.0014212, 0.546501 , 0.4520778], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 2.6429837, -1.4751353, -2.6470933], dtype=float32),\n",
       "  'probabilities': array([0.9791285 , 0.01593541, 0.00493615], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.4031248,  1.8450794,  1.6678157], dtype=float32),\n",
       "  'probabilities': array([0.00771654, 0.5400009 , 0.45228255], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.3751993,  1.8267674,  1.650214 ], dtype=float32),\n",
       "  'probabilities': array([0.00807617, 0.5396304 , 0.45229337], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.9670427,  2.2645397,  2.0797386], dtype=float32),\n",
       "  'probabilities': array([0.00291028, 0.54448   , 0.4526097 ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 3.0681827, -1.7106549, -3.0296218], dtype=float32),\n",
       "  'probabilities': array([0.9894587 , 0.00831716, 0.0022241 ], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-3.8478305,  2.9168627,  2.726493 ], dtype=float32),\n",
       "  'probabilities': array([0.00063125, 0.54710364, 0.45226508], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 2.9564106, -1.6472186, -2.9206035], dtype=float32),\n",
       "  'probabilities': array([0.9873438 , 0.00988866, 0.00276767], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.7980218,  2.139743 ,  1.9568931], dtype=float32),\n",
       "  'probabilities': array([0.00389693, 0.5434595 , 0.45264363], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([ 3.0863047, -1.7261028, -3.0528977], dtype=float32),\n",
       "  'probabilities': array([0.9898198 , 0.00804552, 0.00213469], dtype=float32),\n",
       "  'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.243283 ,  1.7268056,  1.5518911], dtype=float32),\n",
       "  'probabilities': array([0.01015484, 0.53809714, 0.451748  ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.092558 ,  1.6155308,  1.4430183], dtype=float32),\n",
       "  'probabilities': array([0.01314223, 0.535885  , 0.4509728 ], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-3.3907692,  2.5783494,  2.3870656], dtype=float32),\n",
       "  'probabilities': array([0.00139817, 0.5469099 , 0.45169193], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.5610194,  1.9643248,  1.7848959], dtype=float32),\n",
       "  'probabilities': array([0.00586543, 0.5415421 , 0.45259237], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.673944 ,  2.0463037,  1.8658422], dtype=float32),\n",
       "  'probabilities': array([0.00483403, 0.5423589 , 0.45280716], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.0116732,  1.5540233,  1.3831772], dtype=float32),\n",
       "  'probabilities': array([0.01511161, 0.5344083 , 0.45048013], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-2.887149 ,  2.2055237,  2.0217357], dtype=float32),\n",
       "  'probabilities': array([0.00334099, 0.54399455, 0.45266446], dtype=float32),\n",
       "  'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object)}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_predictions # We get a list of dictionaries.\n",
    "#Gives class_ids the class it actually predicted, along with probabilities for each class and other properties.\n",
    "# See how in probability it has chances of being in class 0, 1 or 2\n",
    "# There are logits as well, if you want to look at it from a more mathematical POV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:36.711193Z",
     "start_time": "2019-06-12T13:43:36.706242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([-3.6043298,  2.7369003,  2.5462687], dtype=float32),\n",
       " 'probabilities': array([0.00096386, 0.54698634, 0.45204976], dtype=float32),\n",
       " 'class_ids': array([1], dtype=int64),\n",
       " 'classes': array([b'1'], dtype=object)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:37.989757Z",
     "start_time": "2019-06-12T13:43:37.986746Z"
    }
   },
   "outputs": [],
   "source": [
    "final_preds  = []\n",
    "for pred in note_predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now create a classification report and a Confusion Matrix. Does anything stand out to you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:32:19.761524Z",
     "start_time": "2019-06-12T13:32:19.758481Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:32:24.011083Z",
     "start_time": "2019-06-12T13:32:24.004100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 10  6]\n",
      " [ 0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,final_preds))\n",
    "# Below is the result for batch_size=10,hidden_units=[10, 20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:34:39.360894Z",
     "start_time": "2019-06-12T13:34:39.353912Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.62      0.77        16\n",
      "           2       0.76      1.00      0.86        19\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        45\n",
      "   macro avg       0.92      0.88      0.88        45\n",
      "weighted avg       0.90      0.87      0.86        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))\n",
    "#Try playing with batch size and hidden units upon training, maybe crazy values to see if overfits or not and much more. and\n",
    "# see how it affects your final result.\n",
    "# Below is the result for batch_size=10,hidden_units=[10, 20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:38:50.378006Z",
     "start_time": "2019-06-12T13:38:50.372023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 14  2]\n",
      " [ 0  0 19]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.90      1.00      0.95        19\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.97      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Batch size same, training layers increased\n",
    "print(confusion_matrix(y_test,final_preds))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,final_preds))\n",
    "#Try playing with batch size and hidden units upon training, maybe crazy values to see if overfits or not and much more. and\n",
    "# see how it affects your final result.\n",
    "# Below is the result for batch_size=10 ,hidden_units= [10, 20, 10,15,20,25,30]\n",
    "\n",
    "# CONCLUSION : INCREASED ACCURACY over batch_size = 10 and hidden_units = [10,20,10]. MOST ACCURATE OUT OF ALL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:41:29.088130Z",
     "start_time": "2019-06-12T13:41:29.081149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0 18  1]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.47      1.00      0.64        16\n",
      "           2       1.00      0.05      0.10        19\n",
      "\n",
      "   micro avg       0.60      0.60      0.60        45\n",
      "   macro avg       0.82      0.68      0.58        45\n",
      "weighted avg       0.81      0.60      0.49        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increasing batch size to double 20, and keeping hidden layers as 10,20,10\n",
    "print(confusion_matrix(y_test,final_preds))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,final_preds))\n",
    "#Try playing with batch size and hidden units upon training, maybe crazy values to see if overfits or not and much more. and\n",
    "# see how it affects your final result.\n",
    "# Below is the result for batch_size=20 ,hidden_units= [10,20,10]\n",
    "\n",
    "# CONCLUSION : DECREASE IN ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:43:46.052561Z",
     "start_time": "2019-06-12T13:43:46.045579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0 19  0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.46      1.00      0.63        16\n",
      "           2       0.00      0.00      0.00        19\n",
      "\n",
      "   micro avg       0.58      0.58      0.58        45\n",
      "   macro avg       0.49      0.67      0.54        45\n",
      "weighted avg       0.38      0.58      0.45        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increasing batch size to double 20, and keeping hidden layers as [10,20,10,15,20,25,30]\n",
    "print(confusion_matrix(y_test,final_preds))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,final_preds))\n",
    "#Try playing with batch size and hidden units upon training, maybe crazy values to see if overfits or not and much more. and\n",
    "# see how it affects your final result.\n",
    "# Below is the result for batch_size=20 ,hidden_units= [10,20,10,15,20,25,30]\n",
    "\n",
    "# CONCLUSION : POOR ACCURACY."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
